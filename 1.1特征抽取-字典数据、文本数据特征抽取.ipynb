{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-12T00:50:34.792394Z",
     "start_time": "2020-01-12T00:50:34.789624Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-12T00:53:09.872014Z",
     "start_time": "2020-01-12T00:53:09.866881Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1.0\n",
      "  (0, 3)\t100.0\n",
      "  (1, 2)\t1.0\n",
      "  (1, 3)\t40.0\n",
      "  (2, 0)\t1.0\n",
      "  (2, 3)\t30.0\n"
     ]
    }
   ],
   "source": [
    "# 实例化对象\n",
    "dicvec = DictVectorizer()\n",
    "# 调用fit_transform对字典数据进行特征抽取\n",
    "res = dicvec.fit_transform([{'city':\"北京\", 'temperature':100}, {'city':\"深圳\", 'temperature':40},{'city':\"上海\", 'temperature':30}])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-12T00:53:45.967231Z",
     "start_time": "2020-01-12T00:53:45.961833Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   1.   0. 100.]\n",
      " [  0.   0.   1.  40.]\n",
      " [  1.   0.   0.  30.]]\n"
     ]
    }
   ],
   "source": [
    "# 实例化对象\n",
    "dicvec = DictVectorizer(sparse=False)\n",
    "# sparse参数默认为True,将二维数组转换成scipy的数据格式:sparse\n",
    "\n",
    "# 调用fit_transform对字典数据进行特征抽取\n",
    "res = dicvec.fit_transform([{'city':\"北京\", 'temperature':100}, {'city':\"深圳\", 'temperature':40},{'city':\"上海\", 'temperature':30}])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-12T00:55:34.680518Z",
     "start_time": "2020-01-12T00:55:34.674349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['city=上海', 'city=北京', 'city=深圳', 'temperature']\n",
      "[[  0.   1.   0. 100.]\n",
      " [  0.   0.   1.  40.]\n",
      " [  1.   0.   0.  30.]]\n"
     ]
    }
   ],
   "source": [
    "# 实例化对象\n",
    "dicvec = DictVectorizer(sparse=False)\n",
    "# 调用fit_transform对字典数据进行特征抽取\n",
    "res = dicvec.fit_transform([{'city':\"北京\", 'temperature':100}, {'city':\"深圳\", 'temperature':40},{'city':\"上海\", 'temperature':30}])\n",
    "# 调用get_feature_names获取特征名\n",
    "print(dicvec.get_feature_names())\n",
    "print(res)\n",
    "# 前三列为one-hot编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-12T01:26:44.268716Z",
     "start_time": "2020-01-12T01:26:44.263523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['boring', 'dislike', 'is', 'life', 'python', 'short', 'too', 'use']\n",
      "[[0 0 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# 实例化对象\n",
    "textvec = CountVectorizer()  #没有Sparse参数\n",
    "# 调用fit_transform方法对数据进行特征抽取\n",
    "res = textvec.fit_transform(['life is too short, i use python', 'life is boring, i dislike python'])\n",
    "# print(res)  # 打印一个sparse数组\n",
    "# 获取特征名\n",
    "print(textvec.get_feature_names())\n",
    "# 将sparse数组转换为ndarray\n",
    "print(res.toarray())  # 对每篇文章的字进行分类统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-12T01:36:47.167518Z",
     "start_time": "2020-01-12T01:36:47.159124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我 来到 北京 清华大学\n",
      "他 来到 了 网易 杭研 大厦\n",
      "小明 硕士 毕业 于 中国科学院 计算所 ， 后 在 日本京都大学 深造\n",
      "['中国科学院', '北京', '大厦', '小明', '日本京都大学', '来到', '杭研', '毕业', '深造', '清华大学', '硕士', '网易', '计算所']\n",
      "[[0 1 0 0 0 1 0 0 0 1 0 0 0]\n",
      " [0 0 1 0 0 1 1 0 0 0 0 1 0]\n",
      " [1 0 0 1 1 0 0 1 1 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# 中文分词\n",
    "str1 = \"我来到北京清华大学\"\n",
    "str2 = \"他来到了网易杭研大厦\"\n",
    "str3 = \"小明硕士毕业于中国科学院计算所，后在日本京都大\"\n",
    "\n",
    "import jieba\n",
    "\n",
    "# 对字符串进行分词\n",
    "con1 = jieba.cut(str1)\n",
    "con2 = jieba.cut(str2)\n",
    "con3 = jieba.cut(str3)\n",
    "# 分词返回对象为迭代器\n",
    "\n",
    "# 将迭代器对象转换为list\n",
    "content1 = list(con1)\n",
    "content2 = list(con2)\n",
    "content3 = list(con3)\n",
    "\n",
    "# 将列表转换为字符串\n",
    "c1 = \" \".join(content1)\n",
    "c2 = \" \".join(content2)\n",
    "c3 = \" \".join(content3)\n",
    "\n",
    "print(c1)\n",
    "print(c2)\n",
    "print(c3)\n",
    "\n",
    "# 实例化对象\n",
    "textvec = CountVectorizer()\n",
    "# 特征抽取\n",
    "res = textvec.fit_transform([c1, c2, c3])\n",
    "print(textvec.get_feature_names())\n",
    "print(res.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-12T03:43:23.635364Z",
     "start_time": "2020-01-12T03:43:23.625378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['中国科学院', '北京', '大厦', '小明', '日本京都大学', '来到', '杭研', '毕业', '深造', '清华大学', '硕士', '网易', '计算所']\n",
      "[[0.         0.62276601 0.         0.         0.         0.4736296\n",
      "  0.         0.         0.         0.62276601 0.         0.\n",
      "  0.        ]\n",
      " [0.         0.         0.52863461 0.         0.         0.40204024\n",
      "  0.52863461 0.         0.         0.         0.         0.52863461\n",
      "  0.        ]\n",
      " [0.37796447 0.         0.         0.37796447 0.37796447 0.\n",
      "  0.         0.37796447 0.37796447 0.         0.37796447 0.\n",
      "  0.37796447]]\n"
     ]
    }
   ],
   "source": [
    "# 中文分词\n",
    "str1 = \"我来到北京清华大学\"\n",
    "str2 = \"他来到了网易杭研大厦\"\n",
    "str3 = \"小明硕士毕业于中国科学院计算所，后在日本京都大学深造\"\n",
    "\n",
    "content1 = jieba.cut(str1)\n",
    "content2 = jieba.cut(str2)\n",
    "content3 = jieba.cut(str3)\n",
    "# 返回迭代器对象\n",
    "\n",
    "# 把迭代器转换成list\n",
    "con1 = list(content1)\n",
    "con2 = list(content2)\n",
    "con3 = list(content3)\n",
    "\n",
    "# 转成字符串\n",
    "c1 = \" \".join(con1)\n",
    "c2 = \" \".join(con2)\n",
    "c3 = \" \".join(con3)\n",
    "\n",
    "# 用tfidf特征抽取词的重要性\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 实例化对象\n",
    "td = TfidfVectorizer()\n",
    "# 调用fit_transform()进行特征抽取\n",
    "res = td.fit_transform([c1, c2, c3])\n",
    "print(td.get_feature_names())\n",
    "print(res.toarray())\n",
    "\n",
    "# tf:term frequency:词的频率\n",
    "# idf:inverse document frequency:逆文档频率  log(总的文章数/词出现的文章次数)\n",
    "# tf*idf: 重要性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[[1.         0.         0.         0.        ]\n [0.         1.         1.         0.83333333]\n [0.5        0.5        0.6        1.        ]]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# 数据归一化\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "data = [[90, 2, 10, 40],\n",
    "        [60, 4, 15, 45],\n",
    "        [75, 3, 13, 46]]\n",
    "# 实例化对象\n",
    "mm = MinMaxScaler()\n",
    "res = mm.fit_transform(data)\n",
    "print(res)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
